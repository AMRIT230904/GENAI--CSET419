# -*- coding: utf-8 -*-
"""stable-diffusion-xl-base-1.0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17Zj8EEuQ4br-hvC7cLJGvccZnPuRyAT0
"""

import os
import math
import torch
from diffusers import StableDiffusionPipeline
from PIL import Image
import matplotlib.pyplot as plt

# -----------------------------------
# 1. Device Configuration
# -----------------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using device:", device)

# -----------------------------------
# 2. Load Diffusion Model
# -----------------------------------
model_id = "runwayml/stable-diffusion-v1-5"

pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16 if device == "cuda" else torch.float32
)
pipe = pipe.to(device)
pipe.enable_attention_slicing()

# -----------------------------------
# 3. X-ray Prompts (ALL Labels)
# -----------------------------------
xray_prompts = {
    "Normal": "Chest X-ray image of a healthy human lung, normal radiograph, medical imaging, grayscale",
    "Pneumonia": "Chest X-ray showing lung opacity and consolidation consistent with pneumonia, grayscale radiology image",
    "Tuberculosis": "Chest X-ray showing lung cavities and lesions consistent with tuberculosis, grayscale radiology scan",
    "Lung_Cancer": "Chest X-ray showing a visible lung mass consistent with lung cancer, grayscale medical imaging",
    "COVID19": "Chest X-ray showing bilateral ground-glass opacities consistent with COVID-19 infection, grayscale",
    "Pulmonary_Edema": "Chest X-ray showing bilateral lung haziness and fluid accumulation consistent with pulmonary edema",
    "Pleural_Effusion": "Chest X-ray showing fluid accumulation at lung bases consistent with pleural effusion",
    "Atelectasis": "Chest X-ray showing partial lung collapse consistent with atelectasis",
    "Cardiomegaly": "Chest X-ray showing enlarged cardiac silhouette consistent with cardiomegaly",
    "Pneumothorax": "Chest X-ray showing collapsed lung and pleural line consistent with pneumothorax",
    "Fibrosis": "Chest X-ray showing reticular lung scarring consistent with pulmonary fibrosis"
}

# -----------------------------------
# 4. Dataset Directory
# -----------------------------------
dataset_root = "synthetic_xray_dataset"
os.makedirs(dataset_root, exist_ok=True)

# -----------------------------------
# 5. Generate & Save Images
# -----------------------------------
samples_to_display = []

for label, prompt in xray_prompts.items():
    label_dir = os.path.join(dataset_root, label)
    os.makedirs(label_dir, exist_ok=True)

    image = pipe(
        prompt,
        num_inference_steps=25,
        guidance_scale=7.5
    ).images[0]

    image = image.convert("L")  # grayscale

    image_path = os.path.join(label_dir, f"{label}_01.png")
    image.save(image_path)

    samples_to_display.append((label, image))
    print(f"Saved: {image_path}")

# -----------------------------------
# 6. Display ALL Images (AUTO GRID FIX)
# -----------------------------------
num_images = len(samples_to_display)
cols = 3
rows = math.ceil(num_images / cols)

plt.figure(figsize=(cols * 4, rows * 4))

for i, (label, img) in enumerate(samples_to_display):
    plt.subplot(rows, cols, i + 1)
    plt.imshow(img, cmap="gray")
    plt.title(label)
    plt.axis("off")

plt.tight_layout()
plt.show()

import os
import math
import torch
from diffusers import StableDiffusionPipeline
from PIL import Image
import matplotlib.pyplot as plt

# -----------------------------------
# 1. Device Configuration
# -----------------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using device:", device)

# -----------------------------------
# 2. Load Diffusion Model
# -----------------------------------
model_id = "runwayml/stable-diffusion-v1-5"

pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16 if device == "cuda" else torch.float32
)
pipe = pipe.to(device)
pipe.enable_attention_slicing()

# -----------------------------------
# 3. X-ray Prompts (UNCHANGED)
# -----------------------------------
xray_prompts = {
    "Normal": "Chest X-ray image of a healthy human lung, normal radiograph, medical imaging, grayscale",
    "Pneumonia": "A high-resolution chest X-ray image (frontal view), grayscale medical imaging style, showing lung opacity and consolidation consistent with pneumonia, realistic radiology appearance, hospital diagnostic X-ray, no text, no labels",
    "Tuberculosis": "Chest X-ray of tuberculosis patient, lung lesions and cavities, medical imaging, grayscale",
    "Lung_Cancer": "Chest X-ray showing lung cancer, visible mass in lung region, radiology scan, grayscale",
    "COVID19": "A frontal chest X-ray image showing bilateral ground-glass opacities and patchy lung involvement consistent with COVID-19 infection, grayscale diagnostic X-ray, realistic hospital scan",
    "Pulmonary_Edema": "A chest X-ray showing bilateral lung haziness and fluid accumulation consistent with pulmonary edema, grayscale radiology image, realistic hospital diagnostic scan",
    "Pleural_Effusion": "A frontal chest X-ray showing fluid accumulation at lung bases consistent with pleural effusion, grayscale medical imaging, realistic diagnostic quality",
    "Atelectasis": "A chest X-ray frontal view showing partial lung collapse and reduced lung volume consistent with atelectasis, grayscale radiology image, realistic clinical appearance",
    "Cardiomegaly": "A frontal chest X-ray image showing enlarged cardiac silhouette consistent with cardiomegaly, grayscale diagnostic imaging, realistic hospital X-ray scan",
    "Pneumothorax": "A chest X-ray frontal view showing collapsed lung with visible pleural line consistent with pneumothorax, grayscale medical imaging, high clinical accuracy",
    "Fibrosis": "A chest X-ray image showing reticular lung patterns and scarring consistent with pulmonary fibrosis, grayscale diagnostic radiology scan, realistic hospital imaging",
}

# -----------------------------------
# 4. Dataset Directory
# -----------------------------------
dataset_root = "synthetic_xray_dataset"
os.makedirs(dataset_root, exist_ok=True)

# -----------------------------------
# 5. Generate & Save 3 Images per Category
# -----------------------------------
IMAGES_PER_CLASS = 3
samples_to_display = []

for label, prompt in xray_prompts.items():
    label_dir = os.path.join(dataset_root, label)
    os.makedirs(label_dir, exist_ok=True)

    for i in range(IMAGES_PER_CLASS):
        image = pipe(
            prompt,
            num_inference_steps=25,
            guidance_scale=7.5
        ).images[0]

        image = image.convert("L")  # grayscale

        image_path = os.path.join(label_dir, f"{label}_{i+1:02d}.png")
        image.save(image_path)

        samples_to_display.append((f"{label}_{i+1}", image))
        print(f"Saved: {image_path}")

# -----------------------------------
# 6. Display ALL Images (AUTO GRID)
# -----------------------------------
num_images = len(samples_to_display)
cols = 4
rows = math.ceil(num_images / cols)

plt.figure(figsize=(cols * 4, rows * 4))

for i, (label, img) in enumerate(samples_to_display):
    plt.subplot(rows, cols, i + 1)
    plt.imshow(img, cmap="gray")
    plt.title(label)
    plt.axis("off")

plt.tight_layout()
plt.show()

# =========================================================
# DenseNet Training on Synthetic X-ray Dataset (Single File)
# =========================================================

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, random_split

# ---------------------------------------------------------
# 1. Device Configuration
# ---------------------------------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# ---------------------------------------------------------
# 2. Dataset Path
# ---------------------------------------------------------
DATASET_DIR = "synthetic_xray_dataset"

# ---------------------------------------------------------
# 3. Image Transformations
# DenseNet expects 3-channel (RGB) images
# ---------------------------------------------------------
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# ---------------------------------------------------------
# 4. Load Dataset
# Folder-per-class structure
# ---------------------------------------------------------
dataset = datasets.ImageFolder(root=DATASET_DIR, transform=transform)

class_names = dataset.classes
num_classes = len(class_names)

print("Classes:", class_names)
print("Number of classes:", num_classes)
print("Total images:", len(dataset))

# ---------------------------------------------------------
# 5. Train / Validation Split (80 / 20)
# ---------------------------------------------------------
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size

train_dataset, val_dataset = random_split(
    dataset, [train_size, val_size]
)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)

# ---------------------------------------------------------
# 6. Load DenseNet-121 (Pretrained)
# ---------------------------------------------------------
model = models.densenet121(pretrained=True)

# Replace classifier for multi-class classification
model.classifier = nn.Linear(
    model.classifier.in_features,
    num_classes
)

model = model.to(device)

# ---------------------------------------------------------
# 7. Freeze Backbone (IMPORTANT for small datasets)
# ---------------------------------------------------------
for param in model.features.parameters():
    param.requires_grad = False

# ---------------------------------------------------------
# 8. Loss Function & Optimizer
# ---------------------------------------------------------
criterion = nn.CrossEntropyLoss()

optimizer = optim.Adam(
    model.classifier.parameters(),
    lr=0.001
)

# ---------------------------------------------------------
# 9. Training Loop
# ---------------------------------------------------------
EPOCHS = 15

for epoch in range(EPOCHS):
    # ---- Training ----
    model.train()
    train_loss = 0.0

    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()

    # ---- Validation ----
    model.eval()
    val_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in val_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()

            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    val_accuracy = 100 * correct / total if total > 0 else 0

    print(
        f"Epoch [{epoch+1}/{EPOCHS}] | "
        f"Train Loss: {train_loss / len(train_loader):.4f} | "
        f"Val Loss: {val_loss / len(val_loader):.4f} | "

    )

# ---------------------------------------------------------
# 10. Save Trained Model
# ---------------------------------------------------------
MODEL_PATH = "densenet_synthetic_xray.pth"
torch.save(model.state_dict(), MODEL_PATH)

print("Training complete.")
print("Model saved at:", MODEL_PATH)

import os
import torch
from diffusers import AutoPipelineForText2Image
from PIL import Image

# -------------------------------------------------
# 1. Device Configuration
# -------------------------------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using device:", device)

# -------------------------------------------------
# 2. Load FAST Stable Diffusion Turbo
# -------------------------------------------------
model_id = "stabilityai/sd-turbo"

pipe = AutoPipelineForText2Image.from_pretrained(
    model_id,
    torch_dtype=torch.float16 if device == "cuda" else torch.float32
)
pipe = pipe.to(device)

# -------------------------------------------------
# 3. X-ray Prompts (UNCHANGED)
# -------------------------------------------------
xray_prompts = {
    "Normal": "Chest X-ray image of a healthy human lung, grayscale medical imaging",
    "Pneumonia": "Chest X-ray showing lung opacity and consolidation consistent with pneumonia",
    "Tuberculosis": "Chest X-ray showing lung cavities and lesions consistent with tuberculosis",
    "Lung_Cancer": "Chest X-ray showing visible lung mass consistent with lung cancer",
    "COVID19": "Chest X-ray showing bilateral ground-glass opacities consistent with COVID-19",
    "Pulmonary_Edema": "Chest X-ray showing bilateral lung haziness and fluid accumulation",
    "Pleural_Effusion": "Chest X-ray showing fluid accumulation at lung bases",
    "Atelectasis": "Chest X-ray showing partial lung collapse",
    "Cardiomegaly": "Chest X-ray showing enlarged cardiac silhouette",
    "Pneumothorax": "Chest X-ray showing collapsed lung and pleural line",
    "Fibrosis": "Chest X-ray showing reticular lung scarring"
}

# -------------------------------------------------
# 4. Dataset Directory
# -------------------------------------------------
dataset_root = "synthetic_xray_dataset"
os.makedirs(dataset_root, exist_ok=True)

# -------------------------------------------------
# 5. Generate & Save Images (FAST)
# -------------------------------------------------
IMAGES_PER_CLASS = 20

for label, prompt in xray_prompts.items():
    label_dir = os.path.join(dataset_root, label)
    os.makedirs(label_dir, exist_ok=True)

    print(f"\nGenerating {IMAGES_PER_CLASS} images for {label}")

    for i in range(IMAGES_PER_CLASS):
        image = pipe(
            prompt=prompt,
            num_inference_steps=2,   # ðŸ”¥ Turbo magic
            guidance_scale=0.0
        ).images[0]

        image = image.convert("L")  # grayscale

        image_path = os.path.join(label_dir, f"{label}_{i+1:03d}.png")
        image.save(image_path)

        print(f"Saved: {image_path}")

print("\nâœ… FAST dataset generation complete.")

print("Dataset saved at:", os.path.abspath(dataset_root))

import shutil

shutil.make_archive(
    "synthetic_xray_dataset",
    "zip",
    dataset_root
)

print("Dataset zipped successfully.")

# =====================================================
# Train DenseNet on Synthetic X-ray Dataset
# =====================================================

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, random_split

# -----------------------------------------------------
# 1. Device
# -----------------------------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# -----------------------------------------------------
# 2. Dataset Path
# -----------------------------------------------------
DATASET_DIR = "synthetic_xray_dataset"

# -----------------------------------------------------
# 3. Image Transforms
# (DenseNet expects 3-channel images)
# -----------------------------------------------------
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# -----------------------------------------------------
# 4. Load Dataset
# -----------------------------------------------------
dataset = datasets.ImageFolder(root=DATASET_DIR, transform=transform)

class_names = dataset.classes
num_classes = len(class_names)

print("Classes:", class_names)
print("Number of classes:", num_classes)
print("Total images:", len(dataset))

# -----------------------------------------------------
# 5. Train / Validation Split
# -----------------------------------------------------
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size

train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)

# -----------------------------------------------------
# 6. Load DenseNet-121
# -----------------------------------------------------
model = models.densenet121(pretrained=True)

model.classifier = nn.Linear(
    model.classifier.in_features,
    num_classes
)

model = model.to(device)

# -----------------------------------------------------
# 7. Freeze Backbone (important for small datasets)
# -----------------------------------------------------
for param in model.features.parameters():
    param.requires_grad = False

# -----------------------------------------------------
# 8. Loss & Optimizer
# -----------------------------------------------------
criterion = nn.CrossEntropyLoss()

optimizer = optim.Adam(
    model.classifier.parameters(),
    lr=0.001
)

# -----------------------------------------------------
# 9. Training Loop
# -----------------------------------------------------
EPOCHS = 15

for epoch in range(EPOCHS):
    model.train()
    train_loss = 0.0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()

    # Validation
    model.eval()
    val_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()

            _, preds = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (preds == labels).sum().item()

    val_acc = 100 * correct / total if total > 0 else 0

    print(
        f"Epoch [{epoch+1}/{EPOCHS}] | "
        f"Train Loss: {train_loss/len(train_loader):.4f} | "
        f"Val Loss: {val_loss/len(val_loader):.4f} | "
        f"Val Acc: {val_acc:.2f}%"
    )

# -----------------------------------------------------
# 10. Save Model
# -----------------------------------------------------
torch.save(model.state_dict(), "densenet_synthetic_xray.pth")
print("Model saved as densenet_synthetic_xray.pth")

pip install torch torchvision matplotlib

# ================= FULL DENSENET TRAINING PIPELINE (ONE FLOW) =================

# ---- GPU CHECK ----
import torch
print("GPU Available:", torch.cuda.is_available())

# ---- INSTALL KAGGLE ----
!pip install -q kaggle

# ---- UPLOAD KAGGLE KEY ----
from google.colab import files
files.upload()   # upload kaggle.json

# ---- KAGGLE SETUP ----
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# ---- DOWNLOAD DATASET ----
!kaggle datasets download -d jtiptj/chest-xray-pneumoniacovid19tuberculosis
!unzip -q chest-xray-pneumoniacovid19tuberculosis.zip

# ---- IMPORT LIBRARIES ----
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader

# ---- PARAMETERS ----
IMG_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 10
LR = 0.0001

# ---- DATA TRANSFORMS ----
train_tf = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])

test_tf = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])

# ---- LOAD DATA ----
train_ds = datasets.ImageFolder("chest_xray/train", transform=train_tf)
test_ds  = datasets.ImageFolder("chest_xray/test", transform=test_tf)

train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)

num_classes = len(train_ds.classes)
print("Classes:", train_ds.classes)

# ---- MODEL ----
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = models.densenet121(pretrained=True)
model.classifier = nn.Linear(model.classifier.in_features, num_classes)
model = model.to(device)

# ---- LOSS & OPTIMIZER ----
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LR)

# ---- TRAINING ----
for epoch in range(EPOCHS):
    model.train()
    correct, total, loss_sum = 0, 0, 0

    for x, y in train_loader:
        x, y = x.to(device), y.to(device)

        optimizer.zero_grad()
        out = model(x)
        loss = criterion(out, y)
        loss.backward()
        optimizer.step()

        loss_sum += loss.item()
        _, pred = torch.max(out, 1)
        correct += (pred == y).sum().item()
        total += y.size(0)

    print(f"Epoch {epoch+1}/{EPOCHS} | Loss: {loss_sum:.4f} | Train Acc: {100*correct/total:.2f}%")

# ---- TEST ACCURACY ----
model.eval()
correct, total = 0, 0

with torch.no_grad():
    for x, y in test_loader:
        x, y = x.to(device), y.to(device)
        out = model(x)
        _, pred = torch.max(out, 1)
        correct += (pred == y).sum().item()
        total += y.size(0)

print(f"Test Accuracy: {100*correct/total:.2f}%")

# ---- SAVE MODEL ----
torch.save(model.state_dict(), "densenet_chest_xray.pth")
print("Model Saved")

